{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f763823f",
   "metadata": {},
   "source": [
    "# Ego4D Annotation Verification Notebook\n",
    "## Hello! ðŸ‘‹ \n",
    "Thanks for helping us catch inconsistencies in Ego4D data! This notebook will let you browse annotations on video frames and label them. It's also a great way to sample our dataset.\n",
    "\n",
    "## Prerequisites\n",
    "1. Use the [Ego4D CLI](https://ego4d-data.org/docs/start-here/) to download the annotations and full_scale datasets (you don't need to download any videos)\n",
    "1. Run the downloader with the manifest-only option: `python3 -m ego4d.cli.cli --output_directory ~/ego4d_data/ --manifest --yes`\n",
    "2. Install all the packages in this notebook using `requirements.txt`. iPyWidgets has some nuances, if the widgets at the bottom don't show - follow its [install instructions](https://ipywidgets.readthedocs.io/en/latest/user_install.html).\n",
    "3. Ensure your AWS CLI is authenticated. Follow the [CLI Readme](https://github.com/facebookresearch/Ego4d/blob/main/ego4d/cli/README.md) if it's not.\n",
    "\n",
    "## Process\n",
    "1. Restart the kernel and run all cells in this notebook.\n",
    "1. Scroll to the bottom, input a userid, and begin!\n",
    "1. For each video, mark its annotations 'correct' **or** 'incorrect'. If incorrect, explain why in the notes.\n",
    "1. If you hit errors loading a clip or something doesn't make sense, skip the frame or video.\n",
    "1. Download the csv and send it to a member of the Meta Ego4D team on Slack!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ceb72",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acedc229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set your options here\n",
    "# Sampled Videos will be downloaded to <version>/full_scale/ if they aren't already there\n",
    "\n",
    "CLI_OUTPUT_DIR = \"/Users/<userid>/ego4d\" # Replace with the full path to the --output_directory you pass to the cli\n",
    "VERSION = \"v1\"\n",
    "MANIFEST_PATH = os.path.join(CLI_OUTPUT_DIR, VERSION, 'manifest.csv') # Use this if manifest is at <version>/manifest.csv\n",
    "# MANIFEST_PATH = os.path.join(CLI_OUTPUT_DIR, VERSION, 'full_scale' ,'manifest.csv') # Use this if manifest is at <version>/full_scale/\n",
    "\n",
    "assert os.path.exists(MANIFEST_PATH), f\"Manifest doesn't exist at {MANIFEST_PATH}. Is the CLI_OUTPUT_DIR right? Do you satisfy the pre-requisites?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21edabd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "if os.path.abspath(\".\") not in sys.path: # Allow us to use util files in the same dir\n",
    "    sys.path.insert(0, os.path.abspath(\".\"))\n",
    "\n",
    "import av\n",
    "import base64\n",
    "import boto3\n",
    "import cv2\n",
    "import hashlib\n",
    "import json\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import progressbar\n",
    "import pandas as pd\n",
    "import random\n",
    "import uuid\n",
    "import warnings\n",
    "\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from enum import Enum, auto\n",
    "from IPython.display import HTML, display\n",
    "from ipywidgets import HBox, Layout\n",
    "from ipywidgets.widgets import VBox\n",
    "import ipywidgets as widgets\n",
    "from iopath.common.file_io import PathManager\n",
    "from nb_video_utils import _get_frames\n",
    "from typing import Callable\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "\n",
    "pathmgr = PathManager()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def vid_df_des(df):\n",
    "    return f\"#{len(df)} {df.duration_sec.sum()/60/60:.1f}h\"\n",
    "def vid_des(videos):\n",
    "    return f\"#{len(videos)} {sum((x.duration_sec for x in videos))/60/60:.1f}h\"\n",
    "def deserialize_str_list(list_: str):\n",
    "    list_ = list_[1:-2]\n",
    "    items = list_.split(\"', '\")\n",
    "    return list(map(lambda z: z.strip(\"'\"), items))\n",
    "def to_1D(series):\n",
    "    return pd.Series([x for _list in series for x in _list])\n",
    "\n",
    "config = [\n",
    "    {\n",
    "        'section': 'Annotations Assessment (select one):',\n",
    "        'options': [{\n",
    "            'annotations_correct': {'btn_label': 'Correct', 'btn_color':'#47a84b'},\n",
    "            'annotations_incorrect': {'btn_label':'Incorrect', 'btn_color':'#fb8e26'},\n",
    "        }]\n",
    "    }\n",
    "]\n",
    "option_base_color = \"#b7c2ce\"\n",
    "label_frames_per_video = 10\n",
    "fho_s3_path = \"s3://ego4d-consortium-sharing/annotations/fho_220208.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dd971c",
   "metadata": {},
   "source": [
    "# Load Video Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082afb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 Utils\n",
    "\n",
    "def split_s3_path(s3_path):\n",
    "    path_parts=s3_path.replace(\"s3://\",\"\").split(\"/\")\n",
    "    bucket=path_parts.pop(0)\n",
    "    key=\"/\".join(path_parts)\n",
    "    return bucket, key\n",
    "    \n",
    "\n",
    "def download_from_s3(s3_path, local_path):\n",
    "    print(f\"Downloading {s3_path} -> {local_path}\")\n",
    "    bucket, key = split_s3_path(s3_path)\n",
    "    s3 = boto3.client('s3')\n",
    "    size = s3.head_object(Bucket=bucket, Key=key)['ContentLength']\n",
    "    up_progress = progressbar.progressbar.ProgressBar(maxval=size)\n",
    "    up_progress.start()\n",
    "\n",
    "    def upload_progress(chunk):\n",
    "        up_progress.update(up_progress.currval + chunk)\n",
    "\n",
    "    try:\n",
    "        s3.download_file(bucket, key, local_path, Callback=upload_progress)\n",
    "        up_progress.finish()\n",
    "        print(\"Download Successful\")\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file was not found\")\n",
    "        return False\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f9c13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1 Videos: #9650 3877.9h\n",
      "Downloading s3://ego4d-consortium-sharing/annotations/fho_220202.json -> /Users/eugenebyrne/ego4d/v1/annotations/annotation_verification_fho.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/eugenebyrne/opt/anaconda3/envs/py38/lib/python3.8/site-packages/iopath/common/file_io.py\", line 946, in __log_tmetry_keys\n",
      "    handler.log_event()\n",
      "  File \"/Users/eugenebyrne/opt/anaconda3/envs/py38/lib/python3.8/site-packages/iopath/common/event_logger.py\", line 97, in log_event\n",
      "    del self._evt\n",
      "AttributeError: _evt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download Successful\n",
      "FHO: 1099 videos - top level: dict_keys(['video_data', 'warning_descriptions', 'rejection_descriptions', 'state_changes', 'unmapped_nouns', 'unmapped_verbs', 'date', 'version', 'manifest'])\n",
      "VQ: 1326 videos - top level: dict_keys(['version', 'date', 'description', 'manifest', 'videos'])\n",
      "AV: 153 videos - top level: dict_keys(['date', 'version', 'description', 'videos'])\n"
     ]
    }
   ],
   "source": [
    "# Load video metadata\n",
    "videos_df = pd.read_csv(MANIFEST_PATH)\n",
    "videos_df['scenarios'] = videos_df['scenarios'].apply(deserialize_str_list)\n",
    "def get_video(video_uid):\n",
    "    return videos_df.loc[videos_df['video_uid'] == '353ae622-c322-443e-95b4-e9927dedfa1c'].iloc[0]\n",
    "print(f\"R1 Videos: {vid_df_des(videos_df)}\")\n",
    "\n",
    "# Load FHO\n",
    "fho_local_path = os.path.join(CLI_OUTPUT_DIR, VERSION, 'annotations', 'annotation_verification_fho.json')\n",
    "download_from_s3(fho_s3_path, fho_local_path)\n",
    "with pathmgr.open(fho_local_path, \"r\") as f:\n",
    "    fho_annotations = json.load(f)\n",
    "    fho_ann_video_uids = list(fho_annotations['video_data'].keys())\n",
    "fho_video_dict = fho_annotations['video_data']\n",
    "print(f\"FHO: {len(fho_ann_video_uids)} videos - top level: {fho_annotations.keys()}\")\n",
    "\n",
    "# Load VQ\n",
    "with pathmgr.open(os.path.join(CLI_OUTPUT_DIR, VERSION, 'annotations', 'vq_train.json'), \"r\") as f:\n",
    "    vq_annotations = json.load(f)\n",
    "    vq_ann_video_uids = [x[\"video_uid\"] for x in vq_annotations[\"videos\"]]\n",
    "vq_video_dict = {x[\"video_uid\"]: x[\"clips\"] for x in vq_annotations[\"videos\"]}\n",
    "print(f\"VQ: {len(vq_ann_video_uids)} videos - top level: {vq_annotations.keys()}\")\n",
    "\n",
    "# Load AV\n",
    "with pathmgr.open(os.path.join(CLI_OUTPUT_DIR, VERSION, 'annotations', 'av_train.json'), \"r\") as f:\n",
    "    av_annotations = json.load(f)\n",
    "    av_ann_video_uids = [x[\"video_uid\"] for x in av_annotations[\"videos\"]]\n",
    "av_video_dict = {x[\"video_uid\"]: x[\"clips\"] for x in av_annotations[\"videos\"]}\n",
    "print(f\"AV: {len(av_ann_video_uids)} videos - top level: {av_annotations.keys()}\")\n",
    "\n",
    "class AnnotationType(Enum):\n",
    "    FHO = auto()\n",
    "    VQ = auto()\n",
    "    AV = auto()\n",
    "\n",
    "ANNOTATIONS = {\n",
    "    AnnotationType.FHO: {\n",
    "        'annotations': fho_video_dict,\n",
    "        'video_uids': fho_ann_video_uids\n",
    "    },\n",
    "    AnnotationType.VQ: {\n",
    "        'annotations': vq_video_dict,\n",
    "        'video_uids': vq_ann_video_uids\n",
    "    },\n",
    "    AnnotationType.AV: {\n",
    "        'annotations': av_video_dict,\n",
    "        'video_uids': av_ann_video_uids\n",
    "    }\n",
    "}\n",
    "\n",
    "MANIFEST_DF = videos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963686dd",
   "metadata": {},
   "source": [
    "# Widget Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0564036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulled from https://stackoverflow.com/questions/61708701/how-to-download-a-file-using-ipywidget-button\n",
    "class DownloadButton(widgets.Button):\n",
    "    \"\"\"Download button with dynamic content\n",
    "\n",
    "    The content is generated using a callback when the button is clicked.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename: str, contents: Callable[[], str], **kwargs):\n",
    "        super(DownloadButton, self).__init__(**kwargs)\n",
    "        self.filename = filename\n",
    "        self.contents = contents\n",
    "        self.on_click(self.__on_click)\n",
    "\n",
    "    def __on_click(self, b):\n",
    "        contents: bytes = self.contents().encode('utf-8')\n",
    "        b64 = base64.b64encode(contents)\n",
    "        payload = b64.decode()\n",
    "        digest = hashlib.md5(contents).hexdigest()  # bypass browser cache\n",
    "        id = f'dl_{digest}'\n",
    "\n",
    "        display(HTML(f\"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<a id=\"{id}\" download=\"{self.filename}\" href=\"data:text/csv;base64,{payload}\" download>\n",
    "</a>\n",
    "\n",
    "<script>\n",
    "(function download() {{\n",
    "document.getElementById('{id}').click();\n",
    "}})()\n",
    "</script>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ea123",
   "metadata": {},
   "source": [
    "# Visualization Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31715a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in: video_path, frame_number, boxes: [{ object_type, bbox: {x, y, width, height} }]}, draw_labels\n",
    "# out: path to image of bboxes rendered onto the video frame\n",
    "def render_frame_with_bboxes(video_path, frame_number, boxes, draw_labels = True):\n",
    "    colormap = { # Custom colors for FHO annotations\n",
    "        'object_of_change': (0, 255, 255),\n",
    "        'left_hand': (0, 0, 255),\n",
    "        'right_hand': (0, 255, 0)\n",
    "    }\n",
    "    defaultColor = (255, 255, 0)\n",
    "    rect_thickness = 5\n",
    "    rectLineType = cv2.LINE_4\n",
    "    fontColor = (0, 0, 0)\n",
    "    fontFace = cv2.FONT_HERSHEY_DUPLEX\n",
    "    fontScale = 1\n",
    "    fontThickness = 1\n",
    "    with av.open(video_path) as input_video:\n",
    "        frames = list(_get_frames([frame_number], input_video, include_audio=False, audio_buffer_frames=0))\n",
    "        assert len(frames) == 1\n",
    "        img = frames[0].to_ndarray(format=\"bgr24\")\n",
    "        for box in boxes:\n",
    "            label, bbox = box['object_type'], box['bbox']\n",
    "            rectColor = colormap.get(label, defaultColor) if label else defaultColor\n",
    "            x, y, width, height = list(map(lambda x: int(x), [bbox['x'], bbox['y'], bbox['width'], bbox['height']]))\n",
    "            cv2.rectangle(img, pt1=(x,y), pt2=(x+width, y+height), color=rectColor, thickness=rect_thickness, lineType=rectLineType)\n",
    "            if label and draw_labels:\n",
    "                textSize, baseline = cv2.getTextSize(label, fontFace, fontScale, fontThickness)\n",
    "                textWidth, textHeight = textSize\n",
    "                cv2.rectangle(img, pt1=(x - rect_thickness//2, y - rect_thickness//2), pt2=(x + textWidth + 10 + rect_thickness, y - textHeight - 10 - rect_thickness), color=rectColor, thickness=-1)\n",
    "                cv2.putText(img, text=label, org=(x + 10, y - 10), fontFace=fontFace, fontScale=fontScale, color=fontColor, thickness=fontThickness, lineType=cv2.LINE_AA)\n",
    "    path = f\"/tmp/{frame_number}_{str(uuid.uuid1())}.jpg\"\n",
    "    cv2.imwrite(path, img)\n",
    "    return path\n",
    "\n",
    "# in: video_path, frames: [{ frame_number, frame_type, boxes: [{ object_type, bbox: {x, y, width, height} }] }]\n",
    "# out: void; as a side-effect, renders frames from the video with matplotlib\n",
    "def plot_frames_with_bboxes(video_path, frames, max_cols = 3):\n",
    "    cols = min(max_cols, len(frames))\n",
    "    rows = math.ceil(len(frames) / cols)\n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(10*cols, 7 * rows))\n",
    "    if len(frames) > 1:\n",
    "        [axi.set_axis_off() for axi in axes.ravel()] # Hide axes\n",
    "    for idx, frame_data in enumerate(frames):\n",
    "        row = idx // max_cols\n",
    "        col = idx % max_cols\n",
    "        frame_path = render_frame_with_bboxes(video_path, frame_data['frame_number'], frame_data['boxes'])\n",
    "        axes[row, col].title.set_text(frame_data['frame_type'])\n",
    "        axes[row, col].imshow(mpimg.imread(frame_path, format='jpeg'))\n",
    "    plt.subplots_adjust(wspace=.05, hspace=.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bed212be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AV Data Utils\n",
    "\n",
    "# Aggregate av tracking bounding boxes in an indexable dictionary\n",
    "def get_av_frame_dict(av_video_annotation):\n",
    "    frame_aggregator = {}\n",
    "    for person in av_video_annotation['persons']:\n",
    "        for tracking_path in person['tracking_paths']:\n",
    "            for track in tracking_path['track']:\n",
    "                frame = frame_aggregator.get(track['video_frame'])\n",
    "                if frame is None:\n",
    "                    frame = {\n",
    "                        \"frame_number\": track['video_frame'],\n",
    "                        \"frame_label\": f\"Frame: {track['video_frame']}\",\n",
    "                        \"frame_type\": f\"Frame: {track['video_frame']}\",\n",
    "                        \"boxes\": []\n",
    "                    }\n",
    "                frame['boxes'].append({\n",
    "                    \"object_type\": tracking_path['track_id'],\n",
    "                    \"bbox\": {\n",
    "                        \"x\": track['x'],\n",
    "                        \"y\": track['y'],\n",
    "                        \"width\": track['width'],\n",
    "                        \"height\": track['height']\n",
    "                    }\n",
    "                })\n",
    "                frame_aggregator[track['video_frame']] = frame\n",
    "    return frame_aggregator\n",
    "\n",
    "    \n",
    "# Get ordered list of frames \n",
    "def get_av_frames_with_bboxes(av_video_annotation):\n",
    "    frame_dict = get_av_frame_dict(av_video_annotation)\n",
    "    return sorted(list(frame_dict.values()), key=lambda x: x['frame_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f86c1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dict with frame id info\n",
    "def render_fho(video_path, fho_video_annotations):\n",
    "    # Display critical frames for an action as a grid\n",
    "    interval = random.sample(fho_video_annotations['annotated_intervals'], 1)[0]\n",
    "    actions = list(filter(lambda x: not (x['is_invalid_annotation'] or x['is_rejected']) and x['frames'], interval['narrated_actions']))\n",
    "    action = random.sample(actions, 1)[0]\n",
    "    sample_frame = random.sample(action['frames'], 1)[0]\n",
    "    \n",
    "    frame_path = render_frame_with_bboxes(video_path, sample_frame['frame_number'], sample_frame['boxes'])\n",
    "    plt.rcParams['figure.figsize'] = [15, 10]\n",
    "    plt.imshow(mpimg.imread(frame_path, format='jpeg'))\n",
    "    plt.title(f\"Frame: {sample_frame['frame_number']}\")\n",
    "    plt.show()\n",
    "\n",
    "    #     TODO: add more identifying info\n",
    "    return {\n",
    "        'frame_number': sample_frame['frame_number']\n",
    "    }\n",
    "\n",
    "# returns a dict with frame id info\n",
    "def render_vq(video_path, vq_video_annotations):\n",
    "    annotations = random.sample(vq_video_annotations, 1)[0]['annotations']\n",
    "    query_sets = random.sample(annotations, 1)[0]['query_sets']\n",
    "    sample_query_set = query_sets[random.sample(query_sets.keys(), 1)[0]]\n",
    "    sample_frame = sample_query_set['visual_crop']\n",
    "    box = {\n",
    "        'object_type': sample_query_set['object_title'],\n",
    "        'bbox': {\n",
    "            'x': sample_frame['x'],\n",
    "            'y': sample_frame['y'],\n",
    "            'width': sample_frame['width'],\n",
    "            'height': sample_frame['height'],\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    frame_path = render_frame_with_bboxes(video_path, sample_frame['video_frame_number'], [box])\n",
    "    plt.rcParams['figure.figsize'] = [15, 10]\n",
    "    plt.imshow(mpimg.imread(frame_path, format='jpeg'))\n",
    "    plt.show()\n",
    "    \n",
    "    #     TODO: add more identifying info\n",
    "    return {\n",
    "        'frame_number': sample_frame['video_frame_number']\n",
    "    }\n",
    "\n",
    "# returns a dict with frame id info\n",
    "def render_av(video_path, av_video_annotations):\n",
    "    av_tracked_frames = get_av_frames_with_bboxes(random.sample(av_video_annotations, 1)[0])\n",
    "    sample_frame = random.sample(av_tracked_frames, 1)[0]\n",
    "\n",
    "    frame_path = render_frame_with_bboxes(video_path, sample_frame['frame_number'], sample_frame['boxes'])\n",
    "    plt.rcParams['figure.figsize'] = [15, 10]\n",
    "    plt.imshow(mpimg.imread(frame_path, format='jpeg'))\n",
    "    plt.title(f\"Frame: {sample_frame['frame_number']}\")\n",
    "    plt.show()\n",
    "    \n",
    "    #     TODO: add more identifying info\n",
    "    return {\n",
    "        'frame_number': sample_frame['frame_number']\n",
    "    }\n",
    "\n",
    "def render_frame_with_annotations(video_path, video_annotations, annotation_type):\n",
    "    return {\n",
    "        AnnotationType.FHO: render_fho,\n",
    "        AnnotationType.VQ: render_vq,\n",
    "        AnnotationType.AV: render_av,\n",
    "    }[annotation_type](video_path, video_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a1ed3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling_state = {\n",
    "#     'video_uid': None,\n",
    "#     'video_frames_labeled': 0,\n",
    "#     'annotation_type': AnnotationType.FHO\n",
    "#     'decisions_df': pd.DataFrame([])\n",
    "#     'render_identification_info': {}\n",
    "# }\n",
    "\n",
    "# ui_elements = {\n",
    "#     'userid_input': None,\n",
    "#     'buttons': [],\n",
    "#     'textareas': [],\n",
    "#     'textboxes': [],\n",
    "# }\n",
    "\n",
    "# outputs = {\n",
    "#     'downloads': None\n",
    "#     'frames': None\n",
    "#     'logs': None\n",
    "# }\n",
    "    \n",
    "    \n",
    "def get_local_video_path(video_uid):\n",
    "    return os.path.join(CLI_OUTPUT_DIR, VERSION, 'full_scale', video_uid)\n",
    "    \n",
    "    \n",
    "def load_new_video(outputs, labeling_state, annotation_type):\n",
    "    with outputs['downloads']:\n",
    "        video_uid = random.sample(ANNOTATIONS[annotation_type]['video_uids'], 1)[0]\n",
    "        video_path = get_local_video_path(video_uid)\n",
    "        print(f\"Picked new video: {video_uid} for annotation type: {annotation_type.name}\")\n",
    "        if not os.path.exists(video_path):\n",
    "            s3_path = MANIFEST_DF[MANIFEST_DF.video_uid == video_uid].iloc[0].canonical_s3_location\n",
    "            download_from_s3(s3_path, video_path)\n",
    "        labeling_state['video_uid'] = video_uid\n",
    "        labeling_state['video_frames_labeled'] = 0\n",
    "        labeling_state['annotation_type'] = annotation_type\n",
    "\n",
    "\n",
    "# TODO: Refactor ui disable/enable\n",
    "def load_next_frame(ui_elements, outputs, labeling_state):\n",
    "    annotation_types = list(AnnotationType)\n",
    "    \n",
    "#     Clear Outputs and Disable UI\n",
    "    for out in outputs.values():\n",
    "        out.clear_output()\n",
    "    for elem in [*ui_elements['buttons'], *ui_elements['textareas'], *ui_elements['textboxes'], *ui_elements['dropdowns']]:\n",
    "        elem.disabled = not hasattr(elem, 'enabled_during_refresh')\n",
    "    \n",
    "    if not labeling_state['video_uid'] or labeling_state['video_frames_labeled'] >= label_frames_per_video:\n",
    "#         a_index = annotation_types.index(labeling_state['annotation_type'])\n",
    "#         new_annotation_type = annotation_types[(a_index + 1) % len(annotation_types)]\n",
    "        load_new_video(outputs, labeling_state, labeling_state['annotation_type'])\n",
    "    else:\n",
    "        with outputs['downloads']:\n",
    "            print(f\"Video {labeling_state['video_uid']}: {labeling_state['annotation_type'].name}\")\n",
    "    \n",
    "    video_annotations = ANNOTATIONS[labeling_state['annotation_type']]['annotations'].get(labeling_state['video_uid'])\n",
    "    video_path = get_local_video_path(labeling_state['video_uid'])\n",
    "    \n",
    "    frame_id_info = {}\n",
    "    with outputs['frames']:\n",
    "        frame_id_info = render_frame_with_annotations(video_path, video_annotations, labeling_state['annotation_type'])\n",
    "        \n",
    "    labeling_state['render_identification_info'] = {\n",
    "        'video_uid': labeling_state['video_uid'],\n",
    "        'annotation_type': labeling_state['annotation_type'].name,\n",
    "        **frame_id_info\n",
    "    }\n",
    "    \n",
    "#     Enable UI\n",
    "    for elem in [*ui_elements['buttons'], *ui_elements['textareas'], *ui_elements['textboxes'], *ui_elements['dropdowns']]:\n",
    "        elem.disabled = hasattr(elem, 'disabled_during_labeling')\n",
    "    \n",
    "\n",
    "def get_selections_ui(ui_elements, labeling_state):\n",
    "    userid_textbox = widgets.Text(value='', placeholder='Enter your userid here', description='User Id:')\n",
    "    annotation_type_dropdown = widgets.Dropdown(\n",
    "        options = {\n",
    "            (k, v) for k, v in AnnotationType.__members__.items()\n",
    "        },\n",
    "        description=\"Pick Type:\"\n",
    "    )\n",
    "    \n",
    "    def on_type_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            labeling_state['annotation_type'] = change['new']\n",
    "            labeling_state['video_uid'] = None\n",
    "\n",
    "    annotation_type_dropdown.observe(on_type_change)\n",
    "    annotation_type_dropdown.enabled_at_start = True\n",
    "    \n",
    "    userid_textbox.tag = 'user_id'\n",
    "    userid_textbox.enabled_at_start = True\n",
    "    userid_textbox.disabled_during_labeling = True\n",
    "    userid_textbox.fix_value = True\n",
    "    \n",
    "    ui_elements['dropdowns'] += [annotation_type_dropdown]\n",
    "    ui_elements['textboxes'] += [userid_textbox]\n",
    "    ui_elements['userid_input'] = userid_textbox\n",
    "\n",
    "    row = HBox()\n",
    "    row.children = [userid_textbox, annotation_type_dropdown]\n",
    "    return row\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_notes_textarea_ui(ui_elements):\n",
    "    notes_layout = Layout(width=\"95%\", height=\"100px\")\n",
    "    notes_textarea = widgets.Textarea(\n",
    "        value=\"\",\n",
    "        placeholder=\"Notice anything strange, unique, or interesting? See an incorrect annotation? Add details here!\",\n",
    "        description=\"Notes:\",\n",
    "        disabled=False,\n",
    "        layout=notes_layout\n",
    "    )\n",
    "    notes_textarea.tag = \"notes\"\n",
    "    ui_elements['textareas'] += [notes_textarea]\n",
    "    return notes_textarea\n",
    "\n",
    "\n",
    "def get_options_ui(ui_elements):\n",
    "    btn_layout = Layout(width=\"100%\", height=\"100px\")\n",
    "    btn_style = dict(font_weight='bold')\n",
    "    \n",
    "    def on_option_clicked(b):\n",
    "        b.selected = not b.selected\n",
    "        if b.selected:\n",
    "            b.style.button_color = b.selected_color\n",
    "        else:\n",
    "            b.style.button_color = option_base_color\n",
    "    \n",
    "    ui_sections = []\n",
    "    for section in config:\n",
    "        ui_sections += [widgets.Label(value=section['section'])]\n",
    "        buttons = []\n",
    "        for btn_config in section['options']:\n",
    "            for (decision_string, opt) in btn_config.items():\n",
    "                newBtn = widgets.Button(description=opt['btn_label'], layout=btn_layout, style=btn_style, button_style='success')\n",
    "                newBtn.style.button_color = option_base_color\n",
    "                newBtn.reset_color = option_base_color\n",
    "                newBtn.tag = decision_string\n",
    "                newBtn.selected = False\n",
    "                newBtn.selected_color = opt['btn_color']\n",
    "                newBtn.on_click(on_option_clicked)\n",
    "                buttons += [newBtn]\n",
    "        btn_row = HBox()\n",
    "        btn_row.children = buttons\n",
    "        ui_sections += [btn_row]\n",
    "        ui_elements['buttons'] += buttons\n",
    "    \n",
    "    grid = VBox(layout=Layout(width=\"95%\"))\n",
    "    grid.children = ui_sections\n",
    "    return grid\n",
    "\n",
    "\n",
    "def get_utility_ui(ui_elements, outputs, labeling_state):\n",
    "    begin_btn = widgets.Button(description=\"Start Labeling\")\n",
    "    submit_btn = widgets.Button(description=\"Label Frame\")\n",
    "    download_btn = DownloadButton(filename='ego4d_annotation_labels.csv', contents=lambda: labeling_state['decisions_df'].to_csv(), description='Download CSV')\n",
    "    skip_frame_btn = widgets.Button(description=\"Skip Frame\")\n",
    "    skip_video_btn = widgets.Button(description=\"Skip Video\")\n",
    "    \n",
    "    utility_btns = [begin_btn, submit_btn, download_btn, skip_frame_btn, skip_video_btn]\n",
    "    \n",
    "    def on_begin_btn_clicked(b):\n",
    "        if ui_elements['userid_input'].value == '':\n",
    "            with outputs['logs']:\n",
    "                print(\"Please enter your userid first\")\n",
    "        else:\n",
    "            b.layout.display = 'none'\n",
    "            ui_elements['userid_input'].disabled = True\n",
    "            load_next_frame(ui_elements, outputs, labeling_state)\n",
    "    \n",
    "    def on_submit_btn_clicked(b):\n",
    "        tagged_btns = [btn for btn in ui_elements['buttons'] if hasattr(btn, 'tag')]\n",
    "        tagged_textboxes = [textbox for textbox in ui_elements['textboxes'] if hasattr(textbox, 'tag')]\n",
    "        tagged_textareas = [textarea for textarea in ui_elements['textareas'] if hasattr(textarea, 'tag')]\n",
    "        info_to_log = {\n",
    "            **{btn.tag: btn.selected for btn in tagged_btns},\n",
    "            **{textbox.tag: textbox.value for textbox in tagged_textboxes},\n",
    "            **{textarea.tag: textarea.value for textarea in tagged_textareas},\n",
    "            **labeling_state['render_identification_info']\n",
    "        }\n",
    "        labeling_state['decisions_df'] = labeling_state['decisions_df'].append(info_to_log, ignore_index=True)\n",
    "        labeling_state['video_frames_labeled'] += 1\n",
    "        \n",
    "#         Reset button style and text input contents\n",
    "        for btn in ui_elements['buttons']:\n",
    "            btn.selected = False\n",
    "            if hasattr(btn, 'reset_color'):\n",
    "                btn.style.button_color = btn.reset_color\n",
    "        for textinput in [*ui_elements['textareas'], *ui_elements['textboxes']]:\n",
    "            textinput.value = textinput.value if hasattr(textinput, 'fix_value') else ''\n",
    "        \n",
    "        load_next_frame(ui_elements, outputs, labeling_state)\n",
    "\n",
    "    def on_skip_frame_btn_clicked(b):\n",
    "        load_next_frame(ui_elements, outputs, labeling_state)\n",
    "    \n",
    "    def on_skip_video_btn_clicked(b):\n",
    "        labeling_state['video_uid'] = None\n",
    "        load_next_frame(ui_elements, outputs, labeling_state)\n",
    "        \n",
    "    begin_btn.on_click(on_begin_btn_clicked)\n",
    "    submit_btn.on_click(on_submit_btn_clicked)\n",
    "    skip_frame_btn.on_click(on_skip_frame_btn_clicked)\n",
    "    skip_video_btn.on_click(on_skip_video_btn_clicked)\n",
    "    \n",
    "    begin_btn.enabled_at_start = True\n",
    "#     download_btn.enabled_during_refresh = True\n",
    "#     skip_frame_btn.enabled_during_refresh = True\n",
    "#     skip_video_btn.enabled_during_refresh = True\n",
    "    \n",
    "    ui_elements['buttons'] += utility_btns\n",
    "    \n",
    "    row = HBox()\n",
    "    row.children = utility_btns\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd25cb55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labeling_state = {\n",
    "    'video_uid': None,\n",
    "    'video_frames_labeled': 0,\n",
    "#     'annotation_type': random.sample(list(AnnotationType), 1)[0],\n",
    "    'annotation_type': AnnotationType.VQ,\n",
    "    'decisions_df': pd.DataFrame([]),\n",
    "    'render_identification_info': None\n",
    "}\n",
    "\n",
    "ui_elements = {\n",
    "    'userid_input': None,\n",
    "    'buttons': [],\n",
    "    'textareas': [],\n",
    "    'textboxes': [],\n",
    "    'dropdowns': [],\n",
    "}\n",
    "\n",
    "outputs = {\n",
    "    'downloads': widgets.Output(layout=Layout(height=\"auto\")),\n",
    "    'frames': widgets.Output(layout=Layout(height=\"auto\")),\n",
    "    'logs': widgets.Output(layout=Layout(height=\"auto\"))\n",
    "}\n",
    "\n",
    "ui = [\n",
    "    outputs['downloads'], # Render video download logging info\n",
    "    get_selections_ui(ui_elements, labeling_state), # Render main selections row\n",
    "    outputs['logs'], # Render logs\n",
    "    outputs['frames'], # Render video frames\n",
    "    get_options_ui(ui_elements), # Render options\n",
    "    get_notes_textarea_ui(ui_elements), # Render notes textarea\n",
    "    get_utility_ui(ui_elements, outputs, labeling_state) # Render utility row\n",
    "]\n",
    "\n",
    "# Initially disable UI\n",
    "for elem in [*ui_elements['buttons'], *ui_elements['textareas'], *ui_elements['textboxes'], *ui_elements['dropdowns']]:\n",
    "    elem.disabled = not hasattr(elem, 'enabled_at_start')\n",
    "\n",
    "display(*ui)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
