{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5d807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c01f05-64a6-4b3d-89c0-4038ce019de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189156c-b969-4e81-948c-a29248c3432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a069c-0de0-415a-8849-392614af5935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "taken from\n",
    "https://github.com/marcel-dancak/lz-string-python/blob/master/lzstring.py\n",
    "\"\"\"\n",
    "import math\n",
    "\n",
    "KEYSTRURISAFE = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+-$\"\n",
    "base_reverse_dict = {}\n",
    "\n",
    "\n",
    "class Object:\n",
    "    def __init__(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "\n",
    "def get_base_value(alphabet, character):\n",
    "    if alphabet not in base_reverse_dict:\n",
    "        base_reverse_dict[alphabet] = {}\n",
    "    for i in range(len(alphabet)):\n",
    "        base_reverse_dict[alphabet][alphabet[i]] = i\n",
    "    return base_reverse_dict[alphabet][character]\n",
    "\n",
    "\n",
    "def decompress(length, reset_value, get_next_value):\n",
    "    dictionary = {}\n",
    "    enlarge_in = 4\n",
    "    dict_size = 4\n",
    "    num_bits = 3\n",
    "    entry = \"\"\n",
    "    result = []\n",
    "\n",
    "    data = Object(val=get_next_value(0), position=reset_value, index=1)\n",
    "\n",
    "    for i in range(3):\n",
    "        dictionary[i] = i\n",
    "\n",
    "    bits = 0\n",
    "    maxpower = math.pow(2, 2)\n",
    "    power = 1\n",
    "\n",
    "    while power != maxpower:\n",
    "        resb = data.val & data.position\n",
    "        data.position >>= 1\n",
    "        if data.position == 0:\n",
    "            data.position = reset_value\n",
    "            data.val = get_next_value(data.index)\n",
    "            data.index += 1\n",
    "\n",
    "        bits |= power if resb > 0 else 0\n",
    "        power <<= 1\n",
    "\n",
    "    next = bits\n",
    "    if next == 0:\n",
    "        bits = 0\n",
    "        maxpower = math.pow(2, 8)\n",
    "        power = 1\n",
    "        while power != maxpower:\n",
    "            resb = data.val & data.position\n",
    "            data.position >>= 1\n",
    "            if data.position == 0:\n",
    "                data.position = reset_value\n",
    "                data.val = get_next_value(data.index)\n",
    "                data.index += 1\n",
    "            bits |= power if resb > 0 else 0\n",
    "            power <<= 1\n",
    "        c = chr(bits)\n",
    "    elif next == 1:\n",
    "        bits = 0\n",
    "        maxpower = math.pow(2, 16)\n",
    "        power = 1\n",
    "        while power != maxpower:\n",
    "            resb = data.val & data.position\n",
    "            data.position >>= 1\n",
    "            if data.position == 0:\n",
    "                data.position = reset_value\n",
    "                data.val = get_next_value(data.index)\n",
    "                data.index += 1\n",
    "            bits |= power if resb > 0 else 0\n",
    "            power <<= 1\n",
    "        c = chr(bits)\n",
    "    elif next == 2:\n",
    "        return \"\"\n",
    "\n",
    "    dictionary[3] = c\n",
    "    w = c\n",
    "    result.append(c)\n",
    "    counter = 0\n",
    "    while True:\n",
    "        counter += 1\n",
    "        if data.index > length:\n",
    "            return \"\"\n",
    "\n",
    "        bits = 0\n",
    "        maxpower = math.pow(2, num_bits)\n",
    "        power = 1\n",
    "        while power != maxpower:\n",
    "            resb = data.val & data.position\n",
    "            data.position >>= 1\n",
    "            if data.position == 0:\n",
    "                data.position = reset_value\n",
    "                data.val = get_next_value(data.index)\n",
    "                data.index += 1\n",
    "            bits |= power if resb > 0 else 0\n",
    "            power <<= 1\n",
    "\n",
    "        c = bits\n",
    "        if c == 0:\n",
    "            bits = 0\n",
    "            maxpower = math.pow(2, 8)\n",
    "            power = 1\n",
    "            while power != maxpower:\n",
    "                resb = data.val & data.position\n",
    "                data.position >>= 1\n",
    "                if data.position == 0:\n",
    "                    data.position = reset_value\n",
    "                    data.val = get_next_value(data.index)\n",
    "                    data.index += 1\n",
    "                bits |= power if resb > 0 else 0\n",
    "                power <<= 1\n",
    "\n",
    "            dictionary[dict_size] = chr(bits)\n",
    "            dict_size += 1\n",
    "            c = dict_size - 1\n",
    "            enlarge_in -= 1\n",
    "        elif c == 1:\n",
    "            bits = 0\n",
    "            maxpower = math.pow(2, 16)\n",
    "            power = 1\n",
    "            while power != maxpower:\n",
    "                resb = data.val & data.position\n",
    "                data.position >>= 1\n",
    "                if data.position == 0:\n",
    "                    data.position = reset_value\n",
    "                    data.val = get_next_value(data.index)\n",
    "                    data.index += 1\n",
    "                bits |= power if resb > 0 else 0\n",
    "                power <<= 1\n",
    "            dictionary[dict_size] = chr(bits)\n",
    "            dict_size += 1\n",
    "            c = dict_size - 1\n",
    "            enlarge_in -= 1\n",
    "        elif c == 2:\n",
    "            return \"\".join(result)\n",
    "\n",
    "        if enlarge_in == 0:\n",
    "            enlarge_in = math.pow(2, num_bits)\n",
    "            num_bits += 1\n",
    "\n",
    "        if c in dictionary:\n",
    "            entry = dictionary[c]\n",
    "        else:\n",
    "            if c == dict_size:\n",
    "                entry = w + w[0]\n",
    "            else:\n",
    "                return None\n",
    "        result.append(entry)\n",
    "\n",
    "        # Add w+entry[0] to the dictionary.\n",
    "        dictionary[dict_size] = w + entry[0]\n",
    "        dict_size += 1\n",
    "        enlarge_in -= 1\n",
    "\n",
    "        w = entry\n",
    "        if enlarge_in == 0:\n",
    "            enlarge_in = math.pow(2, num_bits)\n",
    "            num_bits += 1\n",
    "\n",
    "\n",
    "def decompress_from_encoded_uri(compressed):\n",
    "    if compressed is None:\n",
    "        return \"\"\n",
    "    if compressed == \"\":\n",
    "        return None\n",
    "    compressed = compressed.replace(\" \", \"+\")\n",
    "    decompressed = decompress(\n",
    "        len(compressed),\n",
    "        32,\n",
    "        lambda index: get_base_value(KEYSTRURISAFE, compressed[index]),\n",
    "    )\n",
    "\n",
    "    return decompressed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a750ab86-742a-49f9-98f6-8c989503432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools import mask as mask_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5610104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ego4d.research.readers import TorchAudioStreamReader, PyAvReader\n",
    "VideoReader = TorchAudioStreamReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed56e0d-4932-4859-9d53-9e3cc08c7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0cfdcf-39e6-48ae-89b2-b8b6777741f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c564b49-f430-452e-9238-3753f3b02a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "def txt_simm(txt1, txt2):\n",
    "    query_embedding = model.encode(txt1)\n",
    "    passage_embedding = model.encode([txt2])\n",
    "    \n",
    "    return util.dot_score(query_embedding, passage_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a18661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_mask(mask):\n",
    "    w = mask[\"width\"]\n",
    "    h = mask[\"height\"]\n",
    "    encoded_mask = mask[\"encodedMask\"]\n",
    "\n",
    "    decomp_string = decompress_from_encoded_uri(encoded_mask)\n",
    "    decomp_encoded = decomp_string.encode()\n",
    "    rle_obj = {\n",
    "        \"size\": [h, w],\n",
    "        \"counts\": decomp_encoded,\n",
    "    }\n",
    "\n",
    "    output = mask_utils.decode(rle_obj)\n",
    "    return output\n",
    "\n",
    "\n",
    "def blend_mask(input_img, binary_mask, alpha=0.5):\n",
    "    if input_img.ndim == 2:\n",
    "        return input_img\n",
    "\n",
    "    mask_image = np.zeros(input_img.shape, np.uint8)\n",
    "    mask_image[:, :, 1] = 255\n",
    "    mask_image = mask_image * np.repeat(binary_mask[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "    blend_image = input_img[:, :, :]\n",
    "    pos_idx = binary_mask > 0\n",
    "    for ind in range(input_img.ndim):\n",
    "        ch_img1 = input_img[:, :, ind]\n",
    "        ch_img2 = mask_image[:, :, ind]\n",
    "        ch_img3 = blend_image[:, :, ind]\n",
    "        ch_img3[pos_idx] = alpha * ch_img1[pos_idx] + (1 - alpha) * ch_img2[pos_idx]\n",
    "        blend_image[:, :, ind] = ch_img3\n",
    "    return blend_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9859aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEASE_DIR = \"/checkpoint/miguelmartin/egoexo_data/dev\"\n",
    "\n",
    "egoexo = {\n",
    "    \"takes\": os.path.join(RELEASE_DIR, \"takes.json\"),\n",
    "    \"captures\": os.path.join(RELEASE_DIR, \"captures.json\"),\n",
    "    \"physical_setting\": os.path.join(RELEASE_DIR, \"physical_setting.json\"),\n",
    "    \"participants\": os.path.join(RELEASE_DIR, \"participants.json\"),\n",
    "    \"visual_objects\": os.path.join(RELEASE_DIR, \"visual_objects.json\"),\n",
    "}\n",
    "\n",
    "for k, v in egoexo.items():\n",
    "    egoexo[k] = json.load(open(v))\n",
    "\n",
    "takes = egoexo[\"takes\"]\n",
    "captures = egoexo[\"captures\"]\n",
    "takes_by_uid = {x[\"take_uid\"]: x for x in takes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16430fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_dir = os.path.join(RELEASE_DIR, \"annotations/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84881f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "narrs = json.load(open(os.path.join(annotation_dir, \"narrations_latest.json\")))\n",
    "relation_objs = json.load(open(os.path.join(annotation_dir, \"relations_objects_latest.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746066e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "narr_takes = set(narrs.keys())\n",
    "relation_takes = set(relation_objs.keys())\n",
    "len(relation_takes & narr_takes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1142a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = sorted(list(relation_takes & narr_takes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe8bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "take_uid = random.sample(overlap, 1)[0]\n",
    "# take_uid = overlap[0]\n",
    "take_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1116152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = relation_objs[take_uid]\n",
    "\n",
    "object_masks = annotation['object_masks']\n",
    "object_names = [(x, \"\".join(x.split(\"_\")[0])) for x in object_masks.keys()]\n",
    "object_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5189ef-8df2-4049-a682-5dc1c99c8bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "narrs_for_take = [n for narr_pass in narrs[take_uid] for n in narr_pass[\"narrations\"]]\n",
    "narrs_with_simms = []\n",
    "for n in narrs_for_take:\n",
    "    doc = nlp(n[\"text\"])\n",
    "    toks_by_class = defaultdict(list)\n",
    "    for tok in doc:\n",
    "        # toks_by_class[tok.pos_].append((tok, n))\n",
    "        toks_by_class[tok.pos_].append(tok)\n",
    "\n",
    "all_nouns = toks_by_class['NOUN'] + toks_by_class['PROPN']\n",
    "txt_simm_cache = {}\n",
    "for tok in tqdm(all_nouns):\n",
    "    for key, name in object_names:\n",
    "        simm = txt_simm(tok.text, name)\n",
    "        txt_simm_cache[(tok.text, name)] = simm\n",
    "\n",
    "for n in tqdm(narrs_for_take):\n",
    "    matching_objs_per_tok = []\n",
    "    for tok in all_nouns:\n",
    "        matching_objs = {}\n",
    "        for key, name in object_names:\n",
    "            simm_key = (tok.text, name)\n",
    "            assert simm_key in txt_simm_cache\n",
    "            simm = txt_simm_cache[simm_key]\n",
    "            matching_objs[key] = simm.squeeze().cpu().item()\n",
    "        \n",
    "        if len(matching_objs) > 0:\n",
    "            matching_objs_per_tok.append({\"tok_txt\": tok.text, \"tok_idx\": tok.i, \"matches\": matching_objs})\n",
    "    narrs_with_simms.append({\"narration\": n, \"matches\": matching_objs_per_tok})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6e2e75-a30b-4dbf-83c7-9842408e3cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrs_with_simms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bcc041-ca10-4127-ab7c-8c303c8bdb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add pass information\n",
    "SIMM_THRESHOLD = 0.6\n",
    "narrs_with_matches = []\n",
    "for x in narrs_with_simms:\n",
    "    if any(y >= SIMM_THRESHOLD for temp in x[\"matches\"] for y in temp[\"matches\"].values()):\n",
    "        narrs_with_matches.append(x)\n",
    "len(narrs_with_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33803d4b-28a2-485f-aac5-a0b8006e90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrs_with_matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4c6d3-9e49-4cd9-a080-355f460997a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_id_sid = camera_name.split(\"_\")\n",
    "stream_id = \"0\"\n",
    "cam_id = cam_id_sid[0]\n",
    "if len(cam_id_sid) > 1:\n",
    "    cam_id, stream_id = cam_id_sid\n",
    "    if stream_id == \"214-1\":\n",
    "        stream_id = \"rgb\"\n",
    "cam_id, stream_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d09f7c-e79f-420d-a165-9a7f39482e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "takes_by_uid[take_uid][\"frame_aligned_videos\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a17ca6-85a0-4cd9-b919-084f5298fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_path = takes_by_uid[take_uid][\"frame_aligned_videos\"][cam_id][stream_id][\"relative_path\"]\n",
    "video_path = os.path.join(RELEASE_DIR, \"takes\", takes_by_uid[take_uid][\"root_dir\"], rel_path)\n",
    "assert os.path.exists(video_path)\n",
    "\n",
    "reader = VideoReader(path=video_path, resize=None, mean=None, frame_window_size=1, stride=1, gpu_idx=-1)\n",
    "\n",
    "video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6078117-84c0-4334-aca1-2258e7362a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "narr_viz = random.sample(narrs_with_matches, 1)[0]\n",
    "narr_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dda360-83ce-4914-8f32-850753fa6042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "narr_txt = narr_viz[\"narration\"][\"text\"]\n",
    "matched_words = []\n",
    "for ms in narr_viz[\"matches\"]:\n",
    "    for object_name, prob in ms[\"matches\"].items():\n",
    "        if prob >= SIMM_THRESHOLD:\n",
    "            matched_words.append(object_name)\n",
    "matched_words\n",
    "# narr_viz[\"matches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c53ed6-9275-48b3-8639-89d0f68e4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# object_name, object_annotations = random.sample(list(object_masks.items()), 1)[0]\n",
    "# camera_name, mask_annotations = random.sample(list(object_annotations.items()), 1)[0]\n",
    "# frame_number, annotation_obj = random.sample(list(mask_annotations['annotation'].items()), 1)[0]\n",
    "# width, height, encodedMask = itemgetter('width', 'height', 'encodedMask')(annotation_obj)\n",
    "\n",
    "# take_uid, object_name, camera_name, frame_number, width, height, encodedMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed69101-849a-43b7-878a-01da67307987",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = reader[int(frame_number)]\n",
    "mask = decode_mask({\"encodedMask\": encodedMask, \"width\": width, \"height\": height})\n",
    "input_img = frame[0].numpy()\n",
    "pil_img = Image.fromarray(blend_mask(input_img, mask, alpha=0.7))\n",
    "pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c501d-ee7c-4834-8e65-c80f0908f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: cross check with CLIP embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b400c5a-5bdd-49a6-b11c-480d72f9c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab32691-b1ff-49e3-84bb-0bd002b17da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b42b9-040d-49e3-ba5f-d79378d5b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clip_txt_simm(txt1, txt2):\n",
    "#     t1 = clip.tokenize([txt1]).to(device)\n",
    "#     t2 = clip.tokenize([txt2, \"abc\"]).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         t1_features = clip_model.encode_text(t1)\n",
    "#         t2_features = clip_model.encode_text(t2)\n",
    "#         t1_features = t1_features / t1_features.norm(dim=1, keepdim=True)\n",
    "#         t2_features = t2_features / t2_features.norm(dim=1, keepdim=True)\n",
    "#         logit_scale = clip_model.logit_scale.exp()\n",
    "#         logits_pt = logit_scale * t1_features @ t2_features.t()\n",
    "#     probs = logits_pt.softmax(dim=-1).cpu().numpy()\n",
    "#     return probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44f1761-e2d6-48d1-8d88-b0bcd36a11b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip_txt_simm(\"basketball\", \"def\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b830f09b-32f2-4f28-9dcc-054dcd309a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip_txt_simm(\"cat\", \"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552ce43-d409-4bb2-9d3d-85f81fe1faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = preprocess(Image.open(\"CLIP.png\")).unsqueeze(0).to(device)\n",
    "text = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    \n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expert_commentary",
   "language": "python",
   "name": "expert_commentary"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
