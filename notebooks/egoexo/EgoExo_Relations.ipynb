{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5d807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from ego4d.research.util.masks import (\n",
    "    decode_mask,\n",
    "    blend_mask,\n",
    ")\n",
    "from ego4d.research.readers import TorchAudioStreamReader, PyAvReader\n",
    "VideoReader = TorchAudioStreamReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9859aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEASE_DIR = \"/placeholder/path\"  # NOTE: changeme\n",
    "# RELEASE_DIR = \"/large_experiments/egoexo/v2/\"\n",
    "\n",
    "egoexo = {\n",
    "    \"takes\": os.path.join(RELEASE_DIR, \"takes.json\"),\n",
    "    \"captures\": os.path.join(RELEASE_DIR, \"captures.json\"),\n",
    "    \"physical_setting\": os.path.join(RELEASE_DIR, \"physical_setting.json\"),\n",
    "    \"participants\": os.path.join(RELEASE_DIR, \"participants.json\"),\n",
    "    \"visual_objects\": os.path.join(RELEASE_DIR, \"visual_objects.json\"),\n",
    "}\n",
    "\n",
    "for k, v in egoexo.items():\n",
    "    egoexo[k] = json.load(open(v))\n",
    "\n",
    "takes = egoexo[\"takes\"]\n",
    "captures = egoexo[\"captures\"]\n",
    "takes_by_uid = {x[\"take_uid\"]: x for x in takes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16430fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_dir = os.path.join(RELEASE_DIR, \"annotations/\")\n",
    "relation_ann = json.load(open(os.path.join(annotation_dir, \"relations_train.json\")))\n",
    "relation_objs = relation_ann[\"annotations\"]\n",
    "relation_takes = set({k for k, ann in relation_objs.items() if len(ann[\"object_masks\"]) > 0})\n",
    "len(relation_takes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe8bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "take_uid = random.sample(relation_takes, 1)[0]\n",
    "take_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1116152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = relation_objs[take_uid]\n",
    "\n",
    "object_masks = annotation['object_masks']\n",
    "object_names = [(x, \"\".join(x.split(\"_\")[0])) for x in object_masks.keys()]\n",
    "object_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample an object & camera/viewpoint\n",
    "object_name, object_annotations = random.sample(list(object_masks.items()), 1)[0]\n",
    "camera_name, mask_annotations = random.sample(list(object_annotations.items()), 1)[0]\n",
    "\n",
    "cam_id_sid = camera_name.split(\"_\")\n",
    "stream_id = \"0\"\n",
    "cam_id = cam_id_sid[0]\n",
    "if len(cam_id_sid) > 1:\n",
    "    cam_id, stream_id = cam_id_sid\n",
    "    if stream_id == \"214-1\":  # TODO(suyog, miguel): fix inconsitency\n",
    "        stream_id = \"rgb\"\n",
    "\n",
    "rel_path = takes_by_uid[take_uid][\"frame_aligned_videos\"][cam_id][stream_id][\"relative_path\"]\n",
    "video_path = os.path.join(RELEASE_DIR, takes_by_uid[take_uid][\"root_dir\"], rel_path)\n",
    "assert os.path.exists(video_path)\n",
    "\n",
    "reader = VideoReader(\n",
    "    path=video_path,\n",
    "    frame_window_size=1,\n",
    "    stride=1,\n",
    "    gpu_idx=-1,\n",
    "    resize=None,\n",
    "    mean=None,\n",
    "    crop=None,\n",
    "    std=None,\n",
    "    axis_order=\"thwc\",\n",
    "    uint8_scale=True,\n",
    ")\n",
    "object_name, camera_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c53ed6-9275-48b3-8639-89d0f68e4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a frame for the above object + camera\n",
    "frame_number, annotation_obj = random.sample(list(mask_annotations['annotation'].items()), 1)[0]\n",
    "take_uid, object_name, camera_name, frame_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed69101-849a-43b7-878a-01da67307987",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = reader[int(frame_number)]\n",
    "mask = decode_mask(annotation_obj)\n",
    "input_img = frame[\"video\"][0].numpy()\n",
    "pil_img = Image.fromarray(blend_mask(input_img, mask, alpha=0.7))\n",
    "pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c509338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
